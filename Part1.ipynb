{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuongvmu/GCL_DemoCode/blob/main/Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### crop_faces.py\n"
      ],
      "metadata": {
        "id": "fYAjHlRMNGAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from imutils.paths import list_images\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\", required=True, help=\"path to input dataset\")\n",
        "ap.add_argument(\"-o\", \"--output\", required=True, help=\"put to output dataset\")\n",
        "ap.add_argument(\"-p\", \"--prototxt\", required=True, help=\"path to Caffe 'deploy' prototxt file\")\n",
        "ap.add_argument(\"-m\",\"--model\", required=True, help=\"path to Caffe pre-trained model\")\n",
        "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5, help=\"minimum probability to filter weak detection\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "print(\"[INFPO] loading model..\")\n",
        "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
        "if not os.path.exists(args[\"output\"]):\n",
        "    os.makedirs(args[\"output\"])\n",
        "print(\"[INFO] grabbing the names of files and directories...\")\n",
        "names = os.listdir(args[\"dataset\"])\n",
        "\n",
        "print(\"[INFO] starting to crop faces and saving them to disk...\")\n",
        "for name in tqdm(names):\n",
        "    dirPath = os.path.join(args[\"dataset\"], name)\n",
        "    if os.path.isdir(dirPath):\n",
        "        imagePaths = list(list_images(dirPath))\n",
        "        outputDir = os.path.join(args[\"output\"], name)\n",
        "        if not os.path.exists(outputDir):\n",
        "            os.makedirs(outputDir)\n",
        "        for imagePath in imagePaths:\n",
        "            imageID = imagePath.split(os.path.sep)[-1]\n",
        "            image = cv2.imread(imagePath)\n",
        "            (h,w) = image.shape[:2]\n",
        "            blob = cv2.dnn.blobFromImage(cv2.resize(image,\n",
        "                                                    (300,300)), 1.0, (300,300),(104,117.0,123.0))\n",
        "            net.setInput(blob)\n",
        "            detections = net.forward()\n",
        "            i = np.argmax(detections[0,0,:,2])\n",
        "            confidence = detections[0,0,1,2]\n",
        "            if confidence> args[\"confidence\"]:\n",
        "                maxDim = np.max(detections[0,0,i,3:7])\n",
        "                if maxDim >1.0:\n",
        "                    continue\n",
        "                box = np.clip(detections[0,0,i,3:7],0.0,1.0)\n",
        "                box = box * np.array([w,h,w,h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                face = image[startY:endY, startX:endX]\n",
        "                facePath = os.path.join(outputDir, imageID)\n",
        "                cv2.imwrite(facePath, face)\n",
        "\n",
        "print(\"[INFO] finished cropping faces and saving them to disk...\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_XeXf4gbufcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### config.py"
      ],
      "metadata": {
        "id": "dlD3fA_BNDWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import the necessary packages\n",
        "import tensorflow as tf\n",
        "import os\n",
        "# path to training and testing data\n",
        "TRAIN_DATASET = \"cropped_train_dataset\"\n",
        "TEST_DATASET = \"cropped_test_dataset\"\n",
        "# model input image size\n",
        "IMAGE_SIZE = (224, 224)\n",
        "# batch size and the buffer size\n",
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = BATCH_SIZE * 2\n",
        "# define autotune\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "# define the training parameters\n",
        "LEARNING_RATE = 0.0001\n",
        "STEPS_PER_EPOCH = 50\n",
        "VALIDATION_STEPS = 10\n",
        "EPOCHS = 10\n",
        "# define the path to save the model\n",
        "OUTPUT_PATH = \"output\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_PATH, \"siamese_network\")\n",
        "OUTPUT_IMAGE_PATH = os.path.join(OUTPUT_PATH, \"output_image.png\")"
      ],
      "metadata": {
        "id": "EQcYx_kgufe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset.py"
      ],
      "metadata": {
        "id": "Wve9gq1TND4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "class MapFunction():\n",
        "    def __init__(self, imagesize):\n",
        "        self.imagesize = imagesize\n",
        "\n",
        "    def decode_and_resize(self, imagepath):\n",
        "        image = tf.io.read_line(imagepath)\n",
        "        image = tf.image_decode_jpeg(image, channels=3)\n",
        "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "        image = tf.image.resize(image, self.imagesize)\n",
        "        return image\n",
        "\n",
        "    def __call__(self, anchor, positive, negative):\n",
        "        img_anchor = self.decode_and_resize(anchor)\n",
        "        img_positive = self.decode_and_resize(positive)\n",
        "        img_negative = self.decode_and_resize(negative)\n",
        "        return (img_anchor, img_positive, img_negative)\n",
        "\n",
        "\n",
        "class TripletGenerator:\n",
        "    def __init__(self, datasetPath):\n",
        "        self.peopleNames = list()\n",
        "        for folderName in os.listdir(datasetPath):\n",
        "            absoluteFolderName = os.path.join(datasetPath, folderName)\n",
        "            numImages = len(os.listdir(absoluteFolderName))\n",
        "            if numImages > 1:\n",
        "                self.peopleNames.append(absoluteFolderName)\n",
        "        self.allPeople = self.generate_all_people_dict()\n",
        "\n",
        "    def generate_all_people_dict(self):\n",
        "        allPeople = dict()\n",
        "        for personName in self.peopleNames:\n",
        "            imageNames = os.listdir(personName)\n",
        "            personPhotos = [os.path.join(personName, imageName) for imageName in range(imageNames)]\n",
        "            allPeople[personName] = personPhotos\n",
        "        return allPeople\n",
        "\n",
        "    def get_next_element(self):\n",
        "        while True:\n",
        "            anchorName = random.choice(self.peopleNames)\n",
        "            temporaryNames = self.peopleNames.copy()\n",
        "            temporaryNames.remove(anchorName)\n",
        "            negativeName = random.choice(temporaryNames)\n",
        "            (anchorPhoto, positivePhone) = random.choice(\n",
        "                a=self.allPeople[anchorName],\n",
        "                size=2,\n",
        "                replace=False\n",
        "            )\n",
        "            negativePhoto = random.choice(self.allPeople[negativeName])\n",
        "            yield (anchorPhoto, positivePhone, negativePhoto)\n"
      ],
      "metadata": {
        "id": "mBkYlDRzufh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}