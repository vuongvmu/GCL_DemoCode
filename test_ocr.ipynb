{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuongvmu/GCL_DemoCode/blob/main/test_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#V1\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Input, Activation, Conv2D, MaxPooling2D, Conv2DTranspose, Add, concatenate,Flatten,Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import threading\n",
        "\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "tf_ver=tf.__version__\n",
        "\n",
        "def load_labelme_json(json_path):\n",
        "     with open(json_path) as f:\n",
        "          data = json.load(f)\n",
        "     return data\n",
        "def decode_image(data):\n",
        "     image_data=base64.b64decode(str(data['imageData']))\n",
        "     image_np=np.frombuffer(image_data,np.uint8)\n",
        "     image=cv2.imdecode(image_np,cv2.IMREAD_COLOR )#1: IMREAD_COLOR ,0:IMREAD_GRAYSCALE ,-1:IMREAD_UNCHANGED\n",
        "     return image\n",
        "def create_mask(data,image_shape):\n",
        "     mask=np.zeros(image_shape[:2],dtype=np.uint8)\n",
        "     for shape in data['shapes']:\n",
        "          points=np.array(shape['points'],dtype=np.int32)\n",
        "          cv2.fillPoly(mask,[points],color=1)\n",
        "     return mask\n",
        "def get_mask_json(json_data):\n",
        "    mask = np.zeros((json_data['imageHeight'],json_data['imageWidth'], 2), dtype='float32')\n",
        "    for shape in json_data['shapes']:\n",
        "         if(shape['shape_type']!= \"rectangle\") :\n",
        "              continue\n",
        "         points=shape['points']\n",
        "         x1, y1, x2, y2 = int(points[0][0]), int(points[0][1]), int(points[1][0]), int(points[1][1])\n",
        "         w=int( x1+(x2-x1))\n",
        "         h=int( y1+(y2-y1))\n",
        "         if x2 >= json_data['imageWidth'] or y2 >= json_data['imageHeight']:\n",
        "             continue\n",
        "         # Mask char area\n",
        "         mask[y1:y2, x1: x2, 0] = 1\n",
        "         radius = 6\n",
        "\n",
        "         # Mask center point\n",
        "         mask[y1 + h // 2 - radius: y1 + h // 2 + radius + 1, x1 +\n",
        "              w // 2 - radius: x1 + w // 2 + radius + 1, 1] = 1\n",
        "    return mask\n",
        "\n",
        "def preprocess_images_and_mask(json_paths,region=None,target_tensor_shape=(256,256,1)):#region(x,y,h,w) #(h,w,c)\n",
        "     images=[]\n",
        "     masks=[]\n",
        "     for json_path in tqdm( json_paths ,total=len(json_paths),desc=\"Preprocess\"):\n",
        "          data=load_labelme_json(json_path)\n",
        "          image=decode_image(data)\n",
        "\n",
        "          #image=cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "          d = len(image.shape)\n",
        "          if image.shape[2]==3 and target_tensor_shape[2]==1:\n",
        "               image=cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\n",
        "         # mask=create_mask(data, image.shape)\n",
        "          mask=get_mask_json(data)\n",
        "          if region is not None:\n",
        "               image=image[region[1]:region[1] + region[2],region[0]:region[0] + region[3]]\n",
        "               mask=mask[region[1]:region[1] + region[2],region[0]:region[0] + region[3]]\n",
        "          # Chuẩn hóa kích thước image train với đầu vào model\n",
        "          image=cv2.resize(image, (target_tensor_shape[1], target_tensor_shape[0]))\n",
        "          mask=cv2.resize(mask, (target_tensor_shape[1], target_tensor_shape[0]))\n",
        "          mask = np.where(mask < 1, 0, 1)\n",
        "\n",
        "          images.append(image)\n",
        "          masks.append(mask)\n",
        "     return np.array(images),np.array(masks)\n",
        "\n",
        "\n",
        "def creat_tf_dataset(images,masks,batch_size):\n",
        "     masks=to_categorical(masks)\n",
        "     dataset=tf.data.Dataset.from_tensor_silices((images,masks))\n",
        "     dataset=dataset.shuffle(buffer_size=100).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "     return dataset\n",
        "\n",
        "\n",
        "def bn_Conv2d(x, filters=16, kernel_size=(3, 3), padding='same', strides=(1, 1), dilation_rate=(2, 2), name='Conv'):\n",
        "    y = Conv2D(filters=filters, kernel_size=kernel_size, kernel_initializer='he_normal', padding=padding,\n",
        "               strides=strides, dilation_rate=dilation_rate, name=name,kernel_regularizer=l2(0.0001))(x)\n",
        "    y = BatchNormalization(name='BN_' + name)(y)\n",
        "    y = Activation('relu', name='AC_' + name)(y)\n",
        "    return y\n",
        "\n",
        "def bn_Conv2DTranspose(x, filters=16, kernel_size=(3, 3), strides=(2, 2), padding='same', dilation_rate=(1, 1),\n",
        "                       name='transpose', activation='relu'):\n",
        "    up1 = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                          dilation_rate=dilation_rate, name=name)(x)\n",
        "    up1 = BatchNormalization()(up1)\n",
        "    up1 = Activation(activation)(up1)\n",
        "    return up1\n",
        "\n",
        "def Seg_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_block= inputs\n",
        "    p=[]\n",
        "    for i in range(6):\n",
        "        en1 = bn_Conv2d(x=input_block, filters=2**i, kernel_size=(3,3), name='Enc_{0}_1'.format(i+1), dilation_rate=(1,1))\n",
        "        en2 = bn_Conv2d(x=input_block, filters=2 ** (i+1), kernel_size=(3,3), name='Enc_{0}_2'.format(i + 1), dilation_rate=(2,2))\n",
        "        en3 = bn_Conv2d(x=input_block, filters=2 ** (i+2), kernel_size=(3,3), name='Enc_{0}_3'.format(i + 1), dilation_rate=(3,3))\n",
        "        en = concatenate(inputs=[en1, en2, en3],axis=-1)\n",
        "        en= bn_Conv2d(x=en, filters=2 ** (i+2), kernel_size=(1,1), dilation_rate=(1,1), name='Enc_add_{0}'.format(i+1))\n",
        "        p.append(MaxPooling2D(pool_size=(2,2))(en))\n",
        "\n",
        "        input_block=p[i]\n",
        "    trans = bn_Conv2d(x=en, filters=128, kernel_size=(3,3), strides=(2,2), dilation_rate=(1,1), name='transfer')\n",
        "    de = trans\n",
        "    for i in range(5):\n",
        "        de= bn_Conv2DTranspose(x=de, filters=2**(6-i), kernel_size=(3,3), name='Dec_{0}'.format(i+1))\n",
        "        de= Add()([de, p[4-i]])\n",
        "    outputs = bn_Conv2DTranspose(x=de, filters=2, kernel_size=(3,3), name='Dec_6', activation='sigmoid')\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs], name='Segment_model')\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Data generator\n",
        "\n",
        "def data_generator(json_files,region=None,target_shape=(256,256,1), batch_size=8):\n",
        "    while True:\n",
        "        batch_json_files = np.random.choice(json_files, batch_size)\n",
        "\n",
        "        images,masks=preprocess_images_and_mask(batch_json_files,region,target_shape)\n",
        "\n",
        "        images = np.array(images) / 255.0\n",
        "        masks = np.expand_dims(np.array(masks), axis=-1)\n",
        "        yield images, masks\n",
        "# Custom callback\n",
        "class SaveModelAndVisualizeCallback(Callback):\n",
        "    def __init__(self, save_path, val_data,model_name=\"model\", interval=5,num_visualize=2):\n",
        "        super().__init__()\n",
        "        self.save_path = save_path\n",
        "        self.model_name=model_name\n",
        "        self.val_data = val_data\n",
        "        self.interval = interval\n",
        "        self.num_visualize=num_visualize\n",
        "        if not os.path.exists(self.save_path):\n",
        "             os.makedirs(self.save_path)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.interval == 0:\n",
        "            #model_save_path = os.path.join(self.save_path, f'{self.model_name}_epoch_{epoch + 1}.h5')\n",
        "            #self.model.save(model_save_path)\n",
        "            #print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "            # Visualize the predictions\n",
        "            val_images, val_masks = self.val_data\n",
        "            indices=random.sample(range(len(val_images)),self.num_visualize)\n",
        "            image_in=[]\n",
        "            image_true=[]\n",
        "            image_pre=[]\n",
        "            for i,idx in enumerate(indices):\n",
        "                 #print(f\"{i} , {idx}\")\n",
        "                 pred_mask = self.model.predict(np.expand_dims(val_images[idx], axis=0))[0]\n",
        "                 # image_in.append(val_images[idx])\n",
        "                 # image_true.append(val_masks[idx])\n",
        "                 # image_pre.append(pred_mask)\n",
        "                 fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "                 img=np.squeeze(val_images[idx]*255.0)\n",
        "                 ax[0].imshow(img,cmap='gray')\n",
        "                 ax[0].set_title(\"Input Image\")\n",
        "\n",
        "                 ax[1].imshow(np.squeeze(val_masks[idx]),cmap='gray')\n",
        "                 ax[1].set_title(\"True Image\")\n",
        "\n",
        "                 ax[2].imshow(pred_mask.squeeze(), cmap='gray')\n",
        "                 ax[2].set_title(\"Pred Image\")\n",
        "            # plt.show(block=False)\n",
        "            #t =threading.Thread(target= self.show_predict(image_in,image_true,image_pre))\n",
        "            #t.start()\n",
        "    def show_predict(self,image_in,image_true,image_pre):\n",
        "        for i in range(len(image_in)):\n",
        "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            img = np.squeeze(image_in[i])\n",
        "            ax[0].imshow(img, cmap='gray')\n",
        "            ax[0].set_title(\"Input Image\")\n",
        "\n",
        "            ax[1].imshow(np.squeeze(image_true[i]), cmap='gray')\n",
        "            ax[1].set_title(\"True Image\")\n",
        "\n",
        "            ax[2].imshow(np.squeeze(image_pre[i]), cmap='gray')\n",
        "            ax[2].set_title(\"Pred Image\")\n",
        "        plt.show(block=False)\n",
        "# Training function\n",
        "\n",
        "\n",
        "def train_unet(DIR, save_path,model_name, target_shape=(256,256,1), region=(1024,500,512,512),seed=42, batch_size=8, epochs=200):\n",
        "     json_paths=glob(os.path.join(DIR,'*.json'))\n",
        "     json_train_paths,json_test_paths=train_test_split(json_paths,test_size=0.1,random_state=42)\n",
        "     json_train_paths,json_val_paths=train_test_split(json_train_paths,test_size=0.2,random_state=42)\n",
        "\n",
        "     train_images,train_masks=preprocess_images_and_mask(json_train_paths,region,target_shape)\n",
        "\n",
        "     train_images = train_images/255.0\n",
        "     train_masks = np.expand_dims(np.array(train_masks), axis=-1)\n",
        "\n",
        "     print(train_images.shape)\n",
        "\n",
        "     val_images,val_masks=preprocess_images_and_mask(json_val_paths,region,target_shape)\n",
        "     val_images = val_images/255.0\n",
        "     val_masks = np.expand_dims(np.array(val_masks), axis=-1)\n",
        "\n",
        "     # train_gen=data_generator(json_train_paths,batch_size= batch_size)\n",
        "     # val_gen=data_generator(json_val_paths,batch_size= batch_size)\n",
        "\n",
        "     #model = unet_model(input_size=target_shape)\n",
        "     model=Seg_model(input_shape=target_shape)\n",
        "     model.summary()\n",
        "     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "     #Call back\n",
        "     if not os.path.exists(save_path):\n",
        "          os.makedirs(save_path)\n",
        "     csv_path = os.path.join(save_path, 'train_log_' + model_name + '.csv')\n",
        "\n",
        "     val_callback=(val_images,val_masks)\n",
        "\n",
        "     save_and_visualize_callback = SaveModelAndVisualizeCallback(save_path, val_callback, interval=5,num_visualize=5)\n",
        "     callbacks = [\n",
        "        ModelCheckpoint(\n",
        "             os.path.join(save_path,tf_ver+\"_\"+model_name+'-{epoch:03d}--{loss:.6f}-{accuracy:.6f}--{val_loss:.6f}-{val_accuracy:.6f}.h5'),\n",
        "             monitor='val_accuracy', save_best_only=False,\n",
        "            save_weights_only=False, period=10,mode='auto',  verbose=0),\n",
        "       # save_and_visualize_callback,\n",
        "        CSVLogger(csv_path) ,\n",
        "    ]\n",
        "\n",
        "\n",
        "     model.fit(train_images, train_masks, validation_data=(val_images, val_masks), verbose=2, epochs=epochs, batch_size=batch_size,\n",
        "                  callbacks=callbacks, shuffle=True)\n",
        "\n",
        "\n",
        "     # model.fit(train_gen, steps_per_epoch=len(json_train_paths) // batch_size, epochs=epochs,callbacks=[save_and_visualize_callback])\n",
        "\n",
        "\n",
        "\n",
        "data_train=r'F:\\0.Data\\0.Image\\8.OCR\\temp_data'\n",
        "data_out=r'F:\\0.Data\\0.Image\\8.OCR\\temp_data'\n",
        "\n",
        "#json_paths=glob(os.path.join(data_train,'*.json'))\n",
        "\n",
        "train_unet(data_train,data_out,\"OCR\",(256,512,1),None,batch_size=2,epochs=20)\n"
      ],
      "metadata": {
        "id": "XaFEkQEi5xLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_2.py\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Jul  1 10:32:10 2024\n",
        "\n",
        "@author: vuong.tran\n",
        "\"\"\"\n",
        "\n",
        "import copy\n",
        "import time\n",
        "import joblib\n",
        "from functools import wraps\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.cluster import KMeans\n",
        "# from sklearn.externals import joblib as skjoblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skimage import measure\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import base64\n",
        "import random\n",
        "#load image\n",
        "\n",
        "def load_labelme_json(json_path):\n",
        "     with open(json_path) as f:\n",
        "          data = json.load(f)\n",
        "     return data\n",
        "\n",
        "def decode_image(data):\n",
        "     image_data=base64.b64decode(str(data['imageData']))\n",
        "     image_np=np.frombuffer(image_data,np.uint8)\n",
        "     image=cv2.imdecode(image_np,cv2.IMREAD_COLOR )#1: IMREAD_COLOR ,0:IMREAD_GRAYSCALE ,-1:IMREAD_UNCHANGED\n",
        "     return image\n",
        "\n",
        "def norm_mean_std(img):\n",
        "    img = img / 255\n",
        "    img = img.astype('float32')\n",
        "\n",
        "    mean = np.mean(img, axis=(0, 1, 2))\n",
        "    std = np.std(img, axis=(0, 1, 2))\n",
        "\n",
        "    img = (img - mean) / std\n",
        "    return img\n",
        "\n",
        "def get_mask_json(json_data):\n",
        "    mask = np.zeros((json_data['imageHeight'],json_data['imageWidth'], 2), dtype='float32')\n",
        "    for shape in json_data['shapes']:\n",
        "         if(shape['shape_type']!= \"rectangle\") :\n",
        "              continue\n",
        "         points=shape['points']\n",
        "         x1, y1, x2, y2 = int(points[0][0]), int(points[0][1]), int(points[1][0]), int(points[1][1])\n",
        "         w=int( x1+(x2-x1))\n",
        "         h=int( y1+(y2-y1))\n",
        "         if x2 >= json_data['imageWidth'] or y2 >= json_data['imageHeight']:\n",
        "             continue\n",
        "         # Mask area\n",
        "         mask[y1:y2, x1: x2, 0] = 1\n",
        "         radius = 6\n",
        "\n",
        "         # Mask center point\n",
        "         mask[y1 + h // 2 - radius: y1 + h // 2 + radius + 1, x1 +\n",
        "              w // 2 - radius: x1 + w // 2 + radius + 1, 1] = 1\n",
        "    return mask\n",
        "\n",
        "def process_image_and_mask(json_paths,target_tensor_shape,n_classes):\n",
        "     X = np.empty((0,target_tensor_shape[0],target_tensor_shape[1], target_tensor_shape[2]))  # noqa\n",
        "     y = np.empty((0, target_tensor_shape[0],target_tensor_shape[1],n_classes))  # noqa\n",
        "\n",
        "     for json_path in tqdm( json_paths ,total=len(json_paths),desc=\"Preprocess\"):\n",
        "          json_data=load_labelme_json(json_path)\n",
        "          image=decode_image(json_data)\n",
        "\n",
        "          mask=get_mask_json(json_data)\n",
        "          image=cv2.resize(image, (target_tensor_shape[1], target_tensor_shape[0]))\n",
        "          if image.shape[2]==3 and target_tensor_shape[2]==1:\n",
        "               image=cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "          image = np.array(image) / 255.0\n",
        "          image= np.expand_dims(image, axis=-1)\n",
        "\n",
        "          mask=cv2.resize(mask, (target_tensor_shape[1], target_tensor_shape[0]))\n",
        "          mask = np.where(mask < 1, 0, 1)\n",
        "\n",
        "          image = image.astype(np.float32)\n",
        "          mask = mask.astype(np.float32)\n",
        "\n",
        "          X = np.vstack((X, np.expand_dims(image, axis=0)))\n",
        "          y = np.vstack((y, np.expand_dims(mask, axis=0)))\n",
        "     assert X.shape[0] == y.shape[0]\n",
        "     return  X, y\n",
        "\n",
        "def batch_activate(x):\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolution_block(x,\n",
        "                      filters,\n",
        "                      size,\n",
        "                      strides=(1, 1),\n",
        "                      padding='same',\n",
        "                      activation=True):\n",
        "    x = layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    if activation:\n",
        "        x = batch_activate(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(block_input,\n",
        "                   num_filters=16,\n",
        "                   use_batch_activate=False):\n",
        "    x = batch_activate(block_input)\n",
        "    x = convolution_block(x, num_filters, (3, 3))\n",
        "    x = convolution_block(x, num_filters, (3, 3), activation=False)\n",
        "    x = layers.Add()([x, block_input])\n",
        "    if use_batch_activate:\n",
        "        x = batch_activate(x)\n",
        "    return x\n",
        "\n",
        "def resnet_unet(input_shape=(512, 512,1),\n",
        "                start_kernel=32,\n",
        "                dropout_rate=0.25):\n",
        "\n",
        "    # inner\n",
        "    input_layer = layers.Input(name='Inputs',\n",
        "                               shape=input_shape,  # noqa\n",
        "                               dtype='float32')\n",
        "    # down 1\n",
        "    conv1 = layers.Conv2D(start_kernel * 1, (3, 3),\n",
        "                          activation=None, padding=\"same\")(input_layer)\n",
        "    conv1 = residual_block(conv1, start_kernel * 1)\n",
        "    conv1 = residual_block(conv1, start_kernel * 1, True)\n",
        "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = layers.Dropout(dropout_rate)(pool1)\n",
        "\n",
        "    # down 2\n",
        "    conv2 = layers.Conv2D(start_kernel * 2, (3, 3),\n",
        "                          activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = residual_block(conv2, start_kernel * 2)\n",
        "    conv2 = residual_block(conv2, start_kernel * 2, True)\n",
        "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = layers.Dropout(dropout_rate)(pool2)\n",
        "\n",
        "    # down 3\n",
        "    conv3 = layers.Conv2D(start_kernel * 4, (3, 3),\n",
        "                          activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = residual_block(conv3, start_kernel * 4)\n",
        "    conv3 = residual_block(conv3, start_kernel * 4, True)\n",
        "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = layers.Dropout(dropout_rate)(pool3)\n",
        "\n",
        "    # middle\n",
        "    middle = layers.Conv2D(start_kernel * 8, (3, 3),\n",
        "                           activation=None, padding=\"same\")(pool3)\n",
        "    middle = residual_block(middle, start_kernel * 8)\n",
        "    middle = residual_block(middle, start_kernel * 8, True)\n",
        "\n",
        "    # up 1\n",
        "    deconv3 = layers.Conv2DTranspose(\n",
        "        start_kernel * 4, (3, 3), strides=(2, 2), padding=\"same\")(middle)\n",
        "    uconv3 = layers.concatenate([deconv3, conv3])\n",
        "    uconv3 = layers.Dropout(dropout_rate)(uconv3)\n",
        "\n",
        "    uconv3 = layers.Conv2D(start_kernel * 4, (3, 3),\n",
        "                           activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3, start_kernel * 4)\n",
        "    uconv3 = residual_block(uconv3, start_kernel * 4, True)\n",
        "\n",
        "    # up 2\n",
        "    deconv2 = layers.Conv2DTranspose(\n",
        "        start_kernel * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = layers.concatenate([deconv2, conv2])\n",
        "    uconv2 = layers.Dropout(dropout_rate)(uconv2)\n",
        "\n",
        "    uconv2 = layers.Conv2D(start_kernel * 2, (3, 3),\n",
        "                           activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2, start_kernel * 2)\n",
        "    uconv2 = residual_block(uconv2, start_kernel * 2, True)\n",
        "\n",
        "    # up 3\n",
        "    deconv1 = layers.Conv2DTranspose(\n",
        "        start_kernel * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = layers.concatenate([deconv1, conv1])\n",
        "    uconv1 = layers.Dropout(dropout_rate)(uconv1)\n",
        "\n",
        "    uconv1 = layers.Conv2D(start_kernel * 1, (3, 3),\n",
        "                           activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1, start_kernel * 1)\n",
        "    uconv1 = residual_block(uconv1, start_kernel * 1, True)\n",
        "\n",
        "    # output mask\n",
        "    output_layer = layers.Conv2D(\n",
        "        2, (1, 1), padding=\"same\", activation=None)(uconv1)\n",
        "\n",
        "    # 2 classes: character mask & center point mask\n",
        "    output_layer = layers.Activation('sigmoid')(output_layer)\n",
        "\n",
        "    model = models.Model(inputs=[input_layer], outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "#loss defines\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / \\\n",
        "        (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return losses.binary_crossentropy(y_true, y_pred) + \\\n",
        "        dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return losses.binary_crossentropy(y_true, y_pred) - \\\n",
        "        K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "#Metrics\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version\n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "\n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "\n",
        "        # non empty mask case.  Union is never empty\n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "\n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45) * 20)) / 10\n",
        "\n",
        "        metric += iou\n",
        "\n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    # Tensorflow version\n",
        "    return get_iou_vector(label,pred>0.5)\n",
        "    #return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)\n",
        "\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "     def __init__(self,\n",
        "                  json_paths,\n",
        "                  batch_size=1,\n",
        "                  img_size=(512, 512),\n",
        "                  no_channels=3,\n",
        "                  n_classes=2,\n",
        "                  mask_thres=0.5,\n",
        "                  augment=None,\n",
        "                  shuffle=True,\n",
        "                  debug=False):\n",
        "\n",
        "         self.img_size = img_size\n",
        "         self.no_channels = no_channels\n",
        "         self.batch_size = batch_size\n",
        "         print(\">>> Batch_size: {} images\".format(self.batch_size))\n",
        "\n",
        "         self.json_paths = json_paths\n",
        "\n",
        "         self.n_classes = n_classes\n",
        "         self.mask_thres = mask_thres\n",
        "         self.augment = augment\n",
        "         self.shuffle = shuffle\n",
        "         self.on_epoch_end()\n",
        "\n",
        "     def __len__(self):\n",
        "          return int(np.floor(len(self.json_paths) / self.batch_size))\n",
        "     def __getitem__(self, index):\n",
        "         indexes = self.indexes[index *\n",
        "                                self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "         temp_json_path = [self.json_paths[k] for k in indexes]\n",
        "         X, y = self.__data_generation(temp_json_path)\n",
        "\n",
        "         return X, y\n",
        "     def get_data(self):\n",
        "          return self.__getitem__(0)\n",
        "\n",
        "     def on_epoch_end(self):\n",
        "         self.indexes = np.arange(len(self.json_paths))\n",
        "         if self.shuffle:\n",
        "             np.random.shuffle(self.indexes)\n",
        "\n",
        "     def __data_generation(self, json_paths):\n",
        "         return process_image_and_mask(json_paths,target_tensor_shape=(self. img_size[0],self.img_size[1],self.no_channels),n_classes=self.n_classes)\n",
        "\n",
        "# Custom callback\n",
        "class SaveModelAndVisualizeCallback(callbacks):\n",
        "    def __init__(self, save_path, val_data,model_name=\"model\", interval=5,num_visualize=2):\n",
        "        super().__init__()\n",
        "        self.save_path = save_path\n",
        "        self.model_name=model_name\n",
        "        self.val_data = val_data\n",
        "        self.interval = interval\n",
        "        self.num_visualize=num_visualize\n",
        "        if not os.path.exists(self.save_path):\n",
        "             os.makedirs(self.save_path)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.interval == 0:\n",
        "            #model_save_path = os.path.join(self.save_path, f'{self.model_name}_epoch_{epoch + 1}.h5')\n",
        "            #self.model.save(model_save_path)\n",
        "            #print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "            # Visualize the predictions\n",
        "            val_images, val_masks = self.val_data\n",
        "            indices=random.sample(range(len(val_images)),self.num_visualize)\n",
        "            image_in=[]\n",
        "            image_true=[]\n",
        "            image_pre=[]\n",
        "            for i,idx in enumerate(indices):\n",
        "                 #print(f\"{i} , {idx}\")\n",
        "                 pred_mask = self.model.predict(np.expand_dims(val_images[idx], axis=0))[0]\n",
        "                 # image_in.append(val_images[idx])\n",
        "                 # image_true.append(val_masks[idx])\n",
        "                 # image_pre.append(pred_mask)\n",
        "                 fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "                 img=np.squeeze(val_images[idx]*255.0)\n",
        "                 ax[0].imshow(img,cmap='gray')\n",
        "                 ax[0].set_title(\"Input Image\")\n",
        "\n",
        "                 ax[1].imshow(np.squeeze(val_masks[idx]),cmap='gray')\n",
        "                 ax[1].set_title(\"True Image\")\n",
        "\n",
        "                 ax[2].imshow(pred_mask.squeeze(), cmap='gray')\n",
        "                 ax[2].set_title(\"Pred Image\")\n",
        "            # plt.show(block=False)\n",
        "            #t =threading.Thread(target= self.show_predict(image_in,image_true,image_pre))\n",
        "            #t.start()\n",
        "    def show_predict(self,image_in,image_true,image_pre):\n",
        "        for i in range(len(image_in)):\n",
        "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            img = np.squeeze(image_in[i])\n",
        "            ax[0].imshow(img, cmap='gray')\n",
        "            ax[0].set_title(\"Input Image\")\n",
        "\n",
        "            ax[1].imshow(np.squeeze(image_true[i]), cmap='gray')\n",
        "            ax[1].set_title(\"True Image\")\n",
        "\n",
        "            ax[2].imshow(np.squeeze(image_pre[i]), cmap='gray')\n",
        "            ax[2].set_title(\"Pred Image\")\n",
        "        plt.show(block=False)\n",
        "\n",
        "def train():\n",
        "    # Hyperparameter\n",
        "    DATA_STORE=r'F:\\0.Data\\0.Image\\8.OCR'\n",
        "    DATA_DIR=r'F:\\0.Data\\0.Image\\8.OCR\\temp_data'\n",
        "    BATCH_SIZE=8\n",
        "    NUM_CLASS_OUT=2\n",
        "    LR_SEGMENT = 0.01\n",
        "\n",
        "    target_shape=(256,512,1)\n",
        "\n",
        "    net = resnet_unet(\n",
        "         input_shape=target_shape,\n",
        "         start_kernel=16\n",
        "     )\n",
        "    net.summary()\n",
        "\n",
        "    # train / test split\n",
        "    json_paths=glob(os.path.join(DATA_DIR,'*.json'))\n",
        "    json_train_paths,json_val_paths=train_test_split(json_paths,test_size=0.2,random_state=42)\n",
        "\n",
        "    # data generator\n",
        "    train_generator = DataGenerator(\n",
        "        json_train_paths,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        img_size=(target_shape[0], target_shape[1]),\n",
        "        no_channels=target_shape[2],\n",
        "        n_classes=NUM_CLASS_OUT,\n",
        "        shuffle=True,\n",
        "        augment=None,\n",
        "    )\n",
        "    val_generator = DataGenerator(\n",
        "        json_val_paths,\n",
        "        batch_size=1,\n",
        "        img_size=(target_shape[0], target_shape[1]),\n",
        "        no_channels=target_shape[2],\n",
        "        n_classes=NUM_CLASS_OUT,\n",
        "        shuffle=False,\n",
        "        augment=None\n",
        "    )\n",
        "    print(len(train_generator), len(val_generator))\n",
        "\n",
        "    # callbacks\n",
        "    checkpoint = callbacks.ModelCheckpoint(\n",
        "        os.path.join(DATA_STORE, \"ocr_{}_{}_cps.h5\".format(\n",
        "            target_shape, time.time()\n",
        "        )),\n",
        "        monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
        "    )\n",
        "    early = callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", mode=\"min\", patience=4, verbose=1)\n",
        "    redonplat = callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.1, mode=\"min\", patience=3, verbose=1\n",
        "    )\n",
        "    csv_logger = callbacks.CSVLogger(\n",
        "        os.path.join(DATA_STORE, 'ocr_log_{}_{}.csv'.format(\n",
        "            target_shape, time.time()\n",
        "        )),\n",
        "        append=False, separator=','\n",
        "    )\n",
        "\n",
        "    val_callback=val_generator.get_data()\n",
        "    save_and_visualize_callback = SaveModelAndVisualizeCallback(DATA_STORE, val_callback, interval=1,num_visualize=2)\n",
        "\n",
        "\n",
        "\n",
        "    callbacks_list = [\n",
        "        checkpoint,\n",
        "        early,\n",
        "        redonplat,\n",
        "        csv_logger,\n",
        "    ]\n",
        "    # compile\n",
        "    optim = optimizers.Adam(lr=LR_SEGMENT)\n",
        "    net.compile(loss=bce_dice_loss, optimizer=optim,\n",
        "                metrics=[ dice_coef])\n",
        "\n",
        "    # fit model\n",
        "    history = net.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=25,\n",
        "        callbacks=callbacks_list,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(val_generator),\n",
        "    )\n",
        "\n",
        "\n",
        "train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WfOzeN4o52R8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}