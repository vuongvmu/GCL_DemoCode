{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuongvmu/GCL_DemoCode/blob/main/face_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Server/face_model"
      ],
      "metadata": {
        "id": "lI8EfNf5R8-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#config.py\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "TRAIN_DATASET = \"d:/AI_Server/dataset/cropped_train_dataset\"\n",
        "TEST_DATASET = \"d:/AI_Server/dataset/cropped_test_dataset\"\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = BATCH_SIZE * 2\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "STEPS_PER_EPOCH = 50\n",
        "VALIDATION_STEPS = 10\n",
        "EPOCHS = 10\n",
        "\n",
        "OUTPUT_PATH = \"output\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_PATH, \"siamese_network\")\n",
        "OUTPUT_IMAGE_PATH = os.path.join(OUTPUT_PATH, \"output_image.png\")"
      ],
      "metadata": {
        "id": "89HvQxcyR_fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "class MapFunction():\n",
        "    def __init__(self, imagesize):\n",
        "        self.imagesize = imagesize\n",
        "\n",
        "    def decode_and_resize(self, imagepath):\n",
        "        image = tf.io.read_file(imagepath)\n",
        "        image = tf.io.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "        image = tf.image.resize(image, self.imagesize)\n",
        "        return image\n",
        "\n",
        "    def __call__(self, anchor, positive, negative):\n",
        "        img_anchor = self.decode_and_resize(anchor)\n",
        "        img_positive = self.decode_and_resize(positive)\n",
        "        img_negative = self.decode_and_resize(negative)\n",
        "        return (img_anchor, img_positive, img_negative)\n",
        "\n",
        "\n",
        "class TripletGenerator:\n",
        "    def __init__(self, datasetPath):\n",
        "        self.peopleNames = list()\n",
        "        for folderName in os.listdir(datasetPath):\n",
        "            absoluteFolderName = os.path.join(datasetPath, folderName)\n",
        "            numImages = len(os.listdir(absoluteFolderName))\n",
        "            if numImages > 1:\n",
        "                self.peopleNames.append(absoluteFolderName)\n",
        "        self.allPeople = self.generate_all_people_dict()\n",
        "\n",
        "    def generate_all_people_dict(self):\n",
        "        allPeople = dict()\n",
        "        for personName in self.peopleNames:\n",
        "            imageNames = os.listdir(personName)\n",
        "            personPhotos = [os.path.join(personName, imageName) for imageName in imageNames]\n",
        "            allPeople[personName] = personPhotos\n",
        "        return allPeople\n",
        "\n",
        "    def get_next_element(self):\n",
        "        while True:\n",
        "            anchorName = random.choice(self.peopleNames)\n",
        "            temporaryNames = self.peopleNames.copy()\n",
        "            temporaryNames.remove(anchorName)\n",
        "            negativeName = random.choice(temporaryNames)\n",
        "            (anchorPhoto, positivePhone) = random.choices(\n",
        "                self.allPeople[anchorName],\n",
        "                k=2,\n",
        "                # replace=False\n",
        "            )\n",
        "            negativePhoto = random.choice(self.allPeople[negativeName])\n",
        "            yield (anchorPhoto, positivePhone, negativePhoto)\n"
      ],
      "metadata": {
        "id": "lnLMJF1ZR_xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.py\n",
        "from tensorflow.keras.applications import resnet\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_embedding_module(image_size):\n",
        "    inputs = keras.Input(image_size + (3,))\n",
        "    x = resnet.preprocess_input(inputs)\n",
        "    baseCnn = resnet.ResNet50(weights=\"imagenet\", include_top=False)\n",
        "    baseCnn.trainable = False\n",
        "\n",
        "    extractedFeatures = baseCnn(x)\n",
        "    x = layers.GlobalAvgPool2D()(extractedFeatures)\n",
        "    x = layers.Dense(units=1024, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(units=512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(units=256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(units=128)(x)\n",
        "    embedding = keras.Model(inputs, outputs, name=\"embedding\")\n",
        "    return embedding\n",
        "\n",
        "\n",
        "def get_siamese_network(imageSize, embeddingModel):\n",
        "    anchorInput = keras.Input(name=\"anchor\", shape=imageSize + (3,))\n",
        "    positiveInput = keras.Input(name=\"positive\", shape=imageSize + (3,))\n",
        "    negativeInput = keras.Input(name=\"negative\", shape=imageSize + (3,))\n",
        "\n",
        "    anchorEmbedding = embeddingModel(anchorInput)\n",
        "    positiveEmbedding = embeddingModel(positiveInput)\n",
        "    negativeEmbedding = embeddingModel(negativeInput)\n",
        "\n",
        "    siamese_network = keras.Model(\n",
        "        inputs=[anchorInput, positiveInput, negativeInput],\n",
        "        outputs=[anchorEmbedding, positiveEmbedding, negativeEmbedding],\n",
        "        name=\"siameseNetwork\"\n",
        "    )\n",
        "    return siamese_network\n",
        "\n",
        "\n",
        "class SiameseModel(keras.Model):\n",
        "\n",
        "    def __init__(self, siameseNetwork, margin, lossTracker):\n",
        "        super().__init__()\n",
        "        self.siameseNetwork = siameseNetwork\n",
        "        self.margin = margin\n",
        "        self.lossTracker = lossTracker\n",
        "\n",
        "    def _compute_distance(self, inputs):\n",
        "        (anchor, positive, negative) = inputs\n",
        "        embeddings = self.siameseNetwork((anchor, positive, negative))\n",
        "        anchorEmbedding = embeddings[0]\n",
        "        positiveEmbedding = embeddings[1]\n",
        "        negativeEmbedding = embeddings[2]\n",
        "        apDistance = tf.reduce_sum(tf.square(anchorEmbedding - positiveEmbedding), axis=-1)\n",
        "        anDistance = tf.reduce_sum(tf.square(anchorEmbedding - negativeEmbedding), axis=-1)\n",
        "        return (apDistance, anDistance)\n",
        "\n",
        "    def _compute_loss (self, apDistance, anDistance):\n",
        "        loss = apDistance - anDistance\n",
        "        loss = tf.maximum(loss+self.margin,0.0)\n",
        "        return loss\n",
        "\n",
        "    def call(self, inputs):\n",
        "        (apDistance, anDistance) = self._compute_distance(inputs)\n",
        "        return (apDistance, anDistance)\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            (apDistance, anDistance) = self._compute_distance(inputs)\n",
        "            loss = self._compute_loss(apDistance, anDistance)\n",
        "        gradients = tape.gradient(\n",
        "                loss,\n",
        "                self.siameseNetwork.trainable_variables)\n",
        "        self.optimizer.apply_gradients(\n",
        "                zip(gradients, self.siameseNetwork.trainable_variables)\n",
        "            )\n",
        "        self.lossTracker.update_state(loss)\n",
        "        return {\"loss\": self.lossTracker.result()}\n",
        "    def test_step(self, inputs):\n",
        "        (apDistance, anDistance) = self._compute_distance(inputs)\n",
        "        loss = self._compute_loss(apDistance, anDistance)\n",
        "        self.lossTracker.update_state(loss)\n",
        "        return {\"loss\": self.lossTracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.lossTracker]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# image_size = (224, 224)\n",
        "# embedding_model = get_embedding_module(image_size=image_size)\n",
        "# siamese_network = get_siamese_network(image_size, embedding_model)\n",
        "# siamese_network.summary()\n"
      ],
      "metadata": {
        "id": "fdUVO96YR_6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Server"
      ],
      "metadata": {
        "id": "Oe7x50pPSQq_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhfc44qUSiLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crop_faces.py\n",
        "\n",
        "from imutils.paths import list_images\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\",\n",
        "                required=True, help=\"path to input dataset\")\n",
        "ap.add_argument(\"-o\", \"--output\",\n",
        "                required=True, help=\"put to output dataset\")\n",
        "ap.add_argument(\"-p\", \"--prototxt\",\n",
        "                required=True, help=\"path to Caffe 'deploy' prototxt file\")\n",
        "ap.add_argument(\"-m\",\"--model\",\n",
        "                required=True, help=\"path to Caffe pre-trained model\")\n",
        "ap.add_argument(\"-c\", \"--confidence\",\n",
        "                type=float, default=0.5, help=\"minimum probability to filter weak detection\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
        "if not os.path.exists(args[\"output\"]):\n",
        "    os.makedirs(args[\"output\"])\n",
        "\n",
        "\n",
        "names = os.listdir(args[\"dataset\"])\n",
        "\n",
        "\n",
        "for name in tqdm(names):\n",
        "    dirPath = os.path.join(args[\"dataset\"], name)\n",
        "    if os.path.isdir(dirPath):\n",
        "        imagePaths = list(list_images(dirPath))\n",
        "        outputDir = os.path.join(args[\"output\"], name)\n",
        "        if not os.path.exists(outputDir):\n",
        "            os.makedirs(outputDir)\n",
        "        for imagePath in imagePaths:\n",
        "            imageID = imagePath.split(os.path.sep)[-1]\n",
        "            image = cv2.imread(imagePath)\n",
        "            (h,w) = image.shape[:2]\n",
        "            blob = cv2.dnn.blobFromImage(cv2.resize(image,\n",
        "                                                    (300,300)), 1.0,\n",
        "                                         (300,300),(104,117.0,123.0))\n",
        "            net.setInput(blob)\n",
        "            detections = net.forward()\n",
        "            i = np.argmax(detections[0,0,:,2])\n",
        "            confidence = detections[0,0,1,2]\n",
        "            if confidence> args[\"confidence\"]:\n",
        "                maxDim = np.max(detections[0,0,i,3:7])\n",
        "                if maxDim >1.0:\n",
        "                    continue\n",
        "                box = np.clip(detections[0,0,i,3:7],0.0,1.0)\n",
        "                box = box * np.array([w,h,w,h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                face = image[startY:endY, startX:endX]\n",
        "                facePath = os.path.join(outputDir, imageID)\n",
        "                cv2.imwrite(facePath, face)\n",
        "\n",
        "print(\"[INFO] finished cropping faces and saving them to disk...\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PaPM_M49ScWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train.py\n",
        "from face_model.dataset import TripletGenerator\n",
        "from face_model.model import get_embedding_module\n",
        "from face_model.model import get_siamese_network\n",
        "from face_model.model import SiameseModel\n",
        "from face_model.dataset import MapFunction\n",
        "from face_model import config\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "trainTripletGenerator = TripletGenerator(\n",
        "    datasetPath=config.TRAIN_DATASET)\n",
        "\n",
        "valTripletGenerator = TripletGenerator(\n",
        "    datasetPath=config.TRAIN_DATASET)\n",
        "\n",
        "trainTfDataset = tf.data.Dataset.from_generator(\n",
        "    generator=trainTripletGenerator.get_next_element,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "    )\n",
        ")\n",
        "\n",
        "valTfDataset = tf.data.Dataset.from_generator(\n",
        "    generator=valTripletGenerator.get_next_element,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "    )\n",
        ")\n",
        "\n",
        "mapFunction = MapFunction(imagesize=config.IMAGE_SIZE)\n",
        "print(\"[INFO] building the train and validation `tf.data` pipeline...\")\n",
        "\n",
        "trainDs = (trainTfDataset\n",
        "           .map(mapFunction)\n",
        "           .shuffle(config.BUFFER_SIZE)\n",
        "           .batch(config.BATCH_SIZE)\n",
        "           .prefetch(config.AUTO)\n",
        "           )\n",
        "valDs = (valTfDataset\n",
        "         .map(mapFunction)\n",
        "         .batch(config.BATCH_SIZE)\n",
        "         .prefetch(config.AUTO)\n",
        "         )\n",
        "print(\"[INFO] build the siamese model...\")\n",
        "\n",
        "embedingModule = get_embedding_module(image_size=config.IMAGE_SIZE)\n",
        "siameseNetwork = get_siamese_network(\n",
        "    imageSize=config.IMAGE_SIZE,\n",
        "    embeddingModel=embedingModule)\n",
        "siameseModel = SiameseModel(\n",
        "    siameseNetwork=siameseNetwork,\n",
        "    margin=0.5,\n",
        "    lossTracker=keras.metrics.Mean(name='loss'))\n",
        "siameseModel.compile(\n",
        "    optimizer=keras.optimizers.Adam(config.LEARNING_RATE))\n",
        "\n",
        "print(\"[INFO] training the siamese model...\")\n",
        "siameseModel.fit(\n",
        "    trainDs,\n",
        "    steps_per_epoch=config.STEPS_PER_EPOCH,\n",
        "    validation_data=valDs,\n",
        "    validation_steps=config.VALIDATION_STEPS,\n",
        "    epochs=config.EPOCHS\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "if os.path.exists(config.MODEL_PATH):\n",
        "    os.makedirs(config.OUTPUT_PATH)\n",
        "\n",
        "modelPath = config.MODEL_PATH\n",
        "keras.models.save_model(\n",
        "    model=siameseModel.siameseNetwork,\n",
        "    filepath=config.modelPath,\n",
        "    include_optimizer=False)"
      ],
      "metadata": {
        "id": "GVjol8DJScag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test.py\n",
        "from face_model.dataset import TripletGenerator\n",
        "from face_model.dataset import MapFunction\n",
        "from face_model.model import SiameseModel\n",
        "from matplotlib import pyplot as plt\n",
        "from face_model import config\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "testTripletGenerator = TripletGenerator(datasetPath=config.TEST_DATASET)\n",
        "testTfDataset = tf.data.Dataset.from_generator(\n",
        "    generator=testTripletGenerator.get_next_element,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "    ))\n",
        "\n",
        "mapFunction = MapFunction(imagesize=config.IMAGE_SIZE)\n",
        "\n",
        "testDs = (testTfDataset\n",
        "          .map(mapFunction)\n",
        "          .batch(4)\n",
        "          .prefetch(config.AUTO)\n",
        "          )\n",
        "modelPath = config.MODEL_PATH\n",
        "print(f\"[INFO] loading the siamese network from {modelPath}...\")\n",
        "siameseNetwork = keras.models.load_model(filepath=modelPath)\n",
        "siameseModel = SiameseModel(\n",
        "    siameseNetwork=siameseNetwork,\n",
        "    margin=0.5,\n",
        "    lossTracker=keras.metrics.Mean(name=\"loss\"), )\n",
        "# load the test data\n",
        "(anchor, positive, negative) = next(iter(testDs))\n",
        "(apDistance, anDistance) = siameseModel((anchor, positive, negative))\n",
        "plt.figure(figsize=(10, 10))\n",
        "rows = 4\n",
        "for row in range(rows):\n",
        "    plt.subplot(rows, 3, row * 3 + 1)\n",
        "    plt.imshow(anchor[row])\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Anchor image\")\n",
        "    plt.subplot(rows, 3, row * 3 + 2)\n",
        "    plt.imshow(positive[row])\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Positive distance: {apDistance[row]:0.2f}\")\n",
        "    plt.subplot(rows, 3, row * 3 + 3)\n",
        "    plt.imshow(negative[row])\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Negative distance: {anDistance[row]:0.2f}\")\n",
        "# check if the output directory exists, if it doesn't, then\n",
        "# create it\n",
        "if not os.path.exists(config.OUTPUT_PATH):\n",
        "    os.makedirs(config.OUTPUT_PATH)\n",
        "# save the inference image to disk\n",
        "outputImagePath = config.OUTPUT_IMAGE_PATH\n",
        "print(f\"[INFO] saving the inference image to {outputImagePath}...\")\n",
        "plt.savefig(fname=outputImagePath)\n"
      ],
      "metadata": {
        "id": "Ftn-3I4tSm9w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}